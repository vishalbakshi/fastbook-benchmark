{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "uYmwjRe86CQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers -Uqq\n",
        "!pip install -qq RAGatouille\n",
        "!pip install ftfy -qq\n",
        "!pip install llama-index -qq"
      ],
      "metadata": {
        "id": "rS_ILDzb-JyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import is_close\n",
        "from ftfy import fix_text\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from ragatouille.data import CorpusProcessor\n",
        "from llama_index.core.text_splitter import SentenceSplitter\n",
        "\n",
        "corpus_processor = CorpusProcessor()\n",
        "emb_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "id": "biXUKFxZ-PbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to download [utils.py](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/utils.py) and save it locally."
      ],
      "metadata": {
        "id": "zTimC8_vYdgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *"
      ],
      "metadata": {
        "id": "_XxhOhfKYbco"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "ULTHCtvU6D9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbs = download_data()"
      ],
      "metadata": {
        "id": "W6AlmmhTJW4c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nbs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWT0TDvBLpHw",
        "outputId": "92f3b0f4-971f-481d-ebbb-2126ab89f4e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': '01_intro.ipynb',\n",
              " '2': '02_production.ipynb',\n",
              " '4': '04_mnist_basics.ipynb',\n",
              " '8': '08_collab.ipynb',\n",
              " '9': '09_tabular.ipynb',\n",
              " '10': '10_nlp.ipynb',\n",
              " '13': '13_convolutions.ipynb'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark = load_benchmark()\n",
        "data = get_data(nbs)"
      ],
      "metadata": {
        "id": "rHQ7R5zsLqZl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embed Questions and Documents"
      ],
      "metadata": {
        "id": "UzXrTMkf680Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = {}\n",
        "for q in benchmark['questions']: questions.setdefault(str(q['chapter']), []).append(q[\"question_text\"].strip('\"\\''))"
      ],
      "metadata": {
        "id": "VY0VMq7vJbBK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_questions(benchmark):\n",
        "    questions = {}\n",
        "    for q in benchmark['questions']: questions.setdefault(str(q['chapter']), []).append(q[\"question_text\"].strip('\"\\''))\n",
        "    return questions"
      ],
      "metadata": {
        "id": "lpx2iVamMDgd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = prep_questions(benchmark)"
      ],
      "metadata": {
        "id": "VTvdFY7uMIpV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qs_sum = 0\n",
        "for c, qs in questions.items():\n",
        "    print(c, len(qs))\n",
        "    qs_sum += len(qs)\n",
        "assert qs_sum == 191"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Vr2MVMMMIZ",
        "outputId": "446e8da3-e587-43bd-c3fe-63f609c4d660"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 30\n",
            "2 26\n",
            "4 31\n",
            "8 23\n",
            "9 27\n",
            "10 20\n",
            "13 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embed questions\n",
        "qs = questions['1']\n",
        "qs_embs = emb_model.encode(qs, convert_to_tensor=True)\n",
        "qs_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2AkurwLMXaD",
        "outputId": "699166b3-aa17-457e-fac9-4a8475a7fafc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prep data\n",
        "chunk_size = 500\n",
        "documents = process_documents(data['1'], chunk_size=chunk_size)\n",
        "assert len(documents) == 57"
      ],
      "metadata": {
        "id": "HUqAnEOBMf2t"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embed documents\n",
        "data_embs = emb_model.encode(documents, convert_to_tensor=True)\n",
        "data_embs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wBJmwZZMo8_",
        "outputId": "ba795dd3-043a-4274-ec8c-29789d424db4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([57, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top-k Documents by Cosine Similarity"
      ],
      "metadata": {
        "id": "ogNzPiK78Vkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qs_embs.unsqueeze(1).shape, data_embs.unsqueeze(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-foLzxdJdl7",
        "outputId": "85862917-482d-4abc-856d-0e2b79d2396f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([30, 1, 384]), torch.Size([1, 57, 384]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarity\n",
        "idxs = F.cosine_similarity(qs_embs.unsqueeze(1), data_embs.unsqueeze(0), dim=2).sort(descending=True)[1]\n",
        "idxs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezXbUHd4M-Qv",
        "outputId": "310a9dcd-021e-4746-f3b2-072d9b993366"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 57])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk = 10\n",
        "topk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSBLXUiNTXy",
        "outputId": "8237f6f5-07a6-437b-8c1b-34d8b89c716d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_idxs = idxs[:, :topk]\n",
        "top_k_idxs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYJ0K79MNXMA",
        "outputId": "63c6271a-74bf-4afa-c3eb-ad33fcaf7a72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = [row_idxs for row_idxs in top_k_idxs]\n",
        "len(_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sahtb6JnNd1i",
        "outputId": "32305d02-ab90-49a0-ab94-dae0f733613c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3GL0OLQNn9z",
        "outputId": "70b0c378-1cd1-45b7-ef65-60e392f27751"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 41, 10, 13,  9,  5, 42, 11, 43,  6], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_chunks = [[documents[idx.item()] for idx in row_idxs] for row_idxs in top_k_idxs]\n",
        "len(top_k_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS0ijkdINsqA",
        "outputId": "c2141c11-8ef4-49bb-cbe9-891c1df3edcd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(top_k_chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7095X5c3OAAI",
        "outputId": "ff11aef4-5286-40f9-985a-b8708eec1e9a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for o in top_k_chunks: assert len(o) <= topk"
      ],
      "metadata": {
        "id": "ez2Wo94TOEpn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Vector Search for all Chapters"
      ],
      "metadata": {
        "id": "UNWwkS6K9sxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = prep_questions(benchmark)"
      ],
      "metadata": {
        "id": "MeBJ4ZOaJg4b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qs_embs = {}\n",
        "for chapter, qs in questions.items():\n",
        "    qs_embs[chapter] = emb_model.encode(qs, convert_to_tensor=True)\n",
        "    print(c, qs_embs[chapter].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMGLSz3HOZIP",
        "outputId": "a16e5b94-b553-4616-a460-b8cd4c93b712"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 torch.Size([30, 384])\n",
            "13 torch.Size([26, 384])\n",
            "13 torch.Size([31, 384])\n",
            "13 torch.Size([23, 384])\n",
            "13 torch.Size([27, 384])\n",
            "13 torch.Size([20, 384])\n",
            "13 torch.Size([34, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_embs = {}\n",
        "all_docs = {}\n",
        "\n",
        "for chapter, text in data.items():\n",
        "    documents = process_documents(text, chunk_size=chunk_size)\n",
        "    embs = emb_model.encode(documents, convert_to_tensor=True)\n",
        "\n",
        "    all_docs[chapter] = documents\n",
        "    data_embs[chapter] = embs"
      ],
      "metadata": {
        "id": "OBiEzpX5OtFg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def single_vector_retrieval(nbs, all_docs, data_embs, qs_embs, topk=10):\n",
        "    results = []\n",
        "    for chapter in nbs.keys():\n",
        "        idxs = F.cosine_similarity(qs_embs[chapter].unsqueeze(1), data_embs[chapter].unsqueeze(0), dim=2).sort(descending=True)[1]\n",
        "        top_k_idxs = idxs[:, :topk]\n",
        "        top_k_chunks = [[all_docs[chapter][idx.item()] for idx in row_idxs] for row_idxs in top_k_idxs]\n",
        "        results.extend(top_k_chunks)\n",
        "\n",
        "    assert len(results) == 191\n",
        "    for res in results: assert len(res) <= topk\n",
        "    return results"
      ],
      "metadata": {
        "id": "C8ZI0x2wO-qf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = single_vector_retrieval(nbs, all_docs, data_embs, qs_embs)"
      ],
      "metadata": {
        "id": "gb5-7wiNPcij"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrrs, recalls = score_retrieval(benchmark, results)"
      ],
      "metadata": {
        "id": "DuexR2wXPhd1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assertion values below come from [these manual validation results](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024-12-13-fastbook-benchmark-results-MANUAL%20VALIDATION.xlsx) obtained by running [this notebook](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024_12_13_fastbook_benchmark_results.ipynb)."
      ],
      "metadata": {
        "id": "-fjDlbA4Me8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert is_close(mrrs.sum(), 83.33968)\n",
        "assert is_close(mrrs.mean(), 0.43633)\n",
        "assert is_close(recalls.sum(), 154.38333)\n",
        "assert is_close(recalls.mean(), 0.80828)"
      ],
      "metadata": {
        "id": "UWmqdRf3JpET"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}