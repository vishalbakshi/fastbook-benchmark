{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "IgCJ2axbGDta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ijpVyRTF-Q4"
      },
      "outputs": [],
      "source": [
        "!pip install -qq RAGatouille\n",
        "!pip install ftfy -qq\n",
        "!pip install llama-index -qq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from fastcore.test import is_close\n",
        "from ftfy import fix_text\n",
        "from ragatouille import RAGPretrainedModel\n",
        "from ragatouille.data import CorpusProcessor\n",
        "\n",
        "corpus_processor = CorpusProcessor()"
      ],
      "metadata": {
        "id": "aY0yl9tGGG4A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to download [utils.py](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/utils.py) and save it locally."
      ],
      "metadata": {
        "id": "lQHnn1SOagjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *"
      ],
      "metadata": {
        "id": "0mBJbTubagyT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "-4ysJyWVGNld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbs = download_data()\n",
        "nbs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FfNidKVad1s",
        "outputId": "8a509342-72dd-47ec-c32e-a2874e497aa9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': '01_intro.ipynb',\n",
              " '2': '02_production.ipynb',\n",
              " '4': '04_mnist_basics.ipynb',\n",
              " '8': '08_collab.ipynb',\n",
              " '9': '09_tabular.ipynb',\n",
              " '10': '10_nlp.ipynb',\n",
              " '13': '13_convolutions.ipynb'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark = load_benchmark()\n",
        "data = get_data(nbs)\n",
        "questions = prep_questions(benchmark)"
      ],
      "metadata": {
        "id": "CkvRmfrlalT8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Index-Free Retrieval"
      ],
      "metadata": {
        "id": "0MO90qjzGO8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 500\n",
        "chapter = '1'"
      ],
      "metadata": {
        "id": "TxxqxqgjTgOj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = process_documents(data[chapter], chunk_size=chunk_size)\n",
        "assert len(documents) == 57"
      ],
      "metadata": {
        "id": "jqX5dlH3UcwC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = \"colbert-ir/colbertv2.0\"\n",
        "RAG = RAGPretrainedModel.from_pretrained(model_nm)"
      ],
      "metadata": {
        "id": "8xkPPGimTvpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAG.encode(documents, document_metadatas=[{\"chapter\": chapter} for _ in range(len(documents))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4k07VD1UtT-",
        "outputId": "c5e52f68-b0ff-42cb-bf2a-03c2578ce4d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding 57 documents...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "100%|██████████| 2/2 [00:01<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "encodings: torch.Size([57, 508, 128])\n",
            "doc_masks: torch.Size([57, 508])\n",
            "Documents encoded!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk = min(10, len(documents))\n",
        "topk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1zdON_4U8cW",
        "outputId": "031d730c-1969-424e-888c-2784afaf6d7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for q in questions[chapter]:\n",
        "    res = RAG.search_encoded_docs(query = q.strip('\"\\''), k=topk)\n",
        "    res = [r['content'] for r in res]\n",
        "    results.append(res)\n",
        "\n",
        "assert len(results) == 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4NAxqslU-I2",
        "outputId": "da0fc80d-258f-4b72-a37d-b78f3c6726ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[0]"
      ],
      "metadata": {
        "id": "S1ugSBx0VZJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_free_retrieval(nbs, data, questions, model_nm = \"colbert-ir/colbertv2.0\", chunk_size=500):\n",
        "    results = []\n",
        "    for chapter in nbs.keys():\n",
        "        chapter_results = []\n",
        "        RAG = RAGPretrainedModel.from_pretrained(model_nm)\n",
        "        documents = process_documents(data[chapter], chunk_size=chunk_size)\n",
        "        RAG.encode(documents, document_metadatas=[{\"chapter\": chapter} for _ in range(len(documents))])\n",
        "        topk = min(10, len(documents))\n",
        "        for q in questions[chapter]:\n",
        "            res = RAG.search_encoded_docs(query = q.strip('\"\\''), k=topk)\n",
        "            res = [r['content'] for r in res]\n",
        "            chapter_results.append(res)\n",
        "        results.extend(chapter_results)\n",
        "\n",
        "    assert len(results) == 191\n",
        "    for res in results: assert len(res) <= topk\n",
        "    return results"
      ],
      "metadata": {
        "id": "l0n84hb4Vjqx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = index_free_retrieval(nbs, data, questions)"
      ],
      "metadata": {
        "id": "Ar_3xzflWUip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrrs, recalls = score_retrieval(benchmark, results)"
      ],
      "metadata": {
        "id": "5kCWJKyPWdst"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assertion values below come from [these manual validation results](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024-12-13-fastbook-benchmark-results-MANUAL%20VALIDATION.xlsx) obtained by running [this notebook](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024_12_13_fastbook_benchmark_results.ipynb)."
      ],
      "metadata": {
        "id": "j_XcLXpOMgPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert is_close(mrrs.sum(), 107.55119)\n",
        "assert is_close(mrrs.mean(), 0.56309)\n",
        "assert is_close(recalls.sum(), 166.78333)\n",
        "assert is_close(recalls.mean(), 0.873211)"
      ],
      "metadata": {
        "id": "bm9qXaoiTonG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### answerai-colbert-small-v1"
      ],
      "metadata": {
        "id": "_XtwFwt5g-gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = index_free_retrieval(nbs, data, questions, model_nm=\"answerdotai/answerai-colbert-small-v1\")\n",
        "mrrs, recalls = score_retrieval(benchmark, results)"
      ],
      "metadata": {
        "id": "PHnyciQnTptB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert is_close(mrrs.sum(), 109.4246)\n",
        "assert is_close(mrrs.mean(), 0.5729)\n",
        "assert is_close(recalls.sum(), 165.38333)\n",
        "assert is_close(recalls.mean(), 0.86588)"
      ],
      "metadata": {
        "id": "Eno8uBjyWzcV"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}