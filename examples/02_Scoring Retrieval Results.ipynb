{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "dbhDiipgmEaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index -qq\n",
        "!pip install -qq RAGatouille\n",
        "!pip install ftfy -qq\n",
        "\n",
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "import requests\n",
        "from fastcore.test import is_close\n",
        "from ftfy import fix_text\n",
        "from ragatouille.data import CorpusProcessor\n",
        "from llama_index.core.text_splitter import SentenceSplitter\n",
        "\n",
        "corpus_processor = CorpusProcessor()"
      ],
      "metadata": {
        "id": "8xX6bzCrmC5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to download [utils.py](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/utils.py) and save it locally."
      ],
      "metadata": {
        "id": "NFPKe5yYWxVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *"
      ],
      "metadata": {
        "id": "Nda3cI2NV1vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data and Run Search"
      ],
      "metadata": {
        "id": "Meo2qtTJwlzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbs = download_data()\n",
        "nbs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-rkYmnF_9Ao",
        "outputId": "359269d3-7bf1-4666-c315-4cc9bddefcf9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': '01_intro.ipynb',\n",
              " '2': '02_production.ipynb',\n",
              " '4': '04_mnist_basics.ipynb',\n",
              " '8': '08_collab.ipynb',\n",
              " '9': '09_tabular.ipynb',\n",
              " '10': '10_nlp.ipynb',\n",
              " '13': '13_convolutions.ipynb'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_data(nbs)\n",
        "benchmark = load_benchmark()\n",
        "kw_df = load_keywords()"
      ],
      "metadata": {
        "id": "FWZXN_a5Amu-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_path = 'fastbook.db'\n",
        "chunk_size = 500"
      ],
      "metadata": {
        "id": "kO6G_ZlOAv45"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_db()\n",
        "for chapter, text in data.items():\n",
        "    documents = process_documents(text, chunk_size=chunk_size)\n",
        "    assert load_data(documents=documents, db_path=db_path, chapter=chapter)"
      ],
      "metadata": {
        "id": "XwZG0hglA0zI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = full_text_search(kw_df, limit=10)\n",
        "assert len(results) == 191"
      ],
      "metadata": {
        "id": "v0sIee0sBKUS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Successful Retrieval"
      ],
      "metadata": {
        "id": "_UBIb-CkvcTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = benchmark['questions'][0]\n",
        "question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP1l8vUK_-q3",
        "outputId": "8336fd50-ef9a-46cb-c9af-8d297c655ee1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chapter': 1,\n",
              " 'question_number': 1,\n",
              " 'question_text': 'Do you need these for deep learning?\\n\\n- Lots of math T / F\\n   - Lots of data T / F\\n   - Lots of expensive computers T / F\\n   - A PhD T / F',\n",
              " 'gold_standard_answer': '\"Lots of math - False\\nLots of data - False\\nLots of expensive computers - False\\nA PhD - False\"',\n",
              " 'answer_context': [{'answer_component': '\"Lots of math - False\\nLots of data - False\\nLots of expensive computers - False\\nA PhD - False\"',\n",
              "   'scoring_type': 'simple',\n",
              "   'context': ['```asciidoc\\n[[myths]]\\n.What you don\\'t need to do deep learning\\n[options=\"header\"]\\n|======\\n| Myth (don\\'t need) | Truth\\n| Lots of math | Just high school math is sufficient\\n| Lots of data | We\\'ve seen record-breaking results with <50 items of data\\n| Lots of expensive computers | You can get what you need for state of the art work for free\\n|======\\n```'],\n",
              "   'explicit_context': 'true',\n",
              "   'extraneous_answer': 'false'}],\n",
              " 'question_context': []}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question['answer_context'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNXjQjzBBibH",
        "outputId": "d901d8ac-93b7-4fcc-bfcd-020e2a6ead7e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer_component': '\"Lots of math - False\\nLots of data - False\\nLots of expensive computers - False\\nA PhD - False\"',\n",
              " 'scoring_type': 'simple',\n",
              " 'context': ['```asciidoc\\n[[myths]]\\n.What you don\\'t need to do deep learning\\n[options=\"header\"]\\n|======\\n| Myth (don\\'t need) | Truth\\n| Lots of math | Just high school math is sufficient\\n| Lots of data | We\\'ve seen record-breaking results with <50 items of data\\n| Lots of expensive computers | You can get what you need for state of the art work for free\\n|======\\n```'],\n",
              " 'explicit_context': 'true',\n",
              " 'extraneous_answer': 'false'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctx = question['answer_context'][0]['context'][0]\n",
        "ctx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "2klsRLqWBsC_",
        "outputId": "67696580-b1e1-44d9-a568-2d296c03f18e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```asciidoc\\n[[myths]]\\n.What you don\\'t need to do deep learning\\n[options=\"header\"]\\n|======\\n| Myth (don\\'t need) | Truth\\n| Lots of math | Just high school math is sufficient\\n| Lots of data | We\\'ve seen record-breaking results with <50 items of data\\n| Lots of expensive computers | You can get what you need for state of the art work for free\\n|======\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "passage = results[0][1]\n",
        "passage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "ZHCvyT9EBy0G",
        "outputId": "f4c16b5d-9ca7-491e-ad5d-1869acc0ddc7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'#hide\\n! [ -e /content ] && pip install -Uqq fastbook\\nimport fastbook\\nfastbook.setup_book()\\n#hide\\nfrom fastbook import *\\n# Your Deep Learning Journey\\nHello, and thank you for letting us join you on your deep learning journey, however far along that you may be! In this chapter, we will tell you a little bit more about what to expect in this book, introduce the key concepts behind deep learning, and train our first models on different tasks. It doesn\\'t matter if you don\\'t come from a technical or a mathematical background (though it\\'s okay if you do too!); we wrote this book to make deep learning accessible to as many people as possible.\\n## Deep Learning Is for Everyone\\nA lot of people assume that you need all kinds of hard-to-find stuff to get great results with deep learning, but as you\\'ll see in this book, those people are wrong. <<myths>> is a list of a few thing you *absolutely don\\'t need* to do world-class deep learning.\\n\\n```asciidoc\\n[[myths]]\\n.What you don\\'t need to do deep learning\\n[options=\"header\"]\\n|======\\n| Myth (don\\'t need) | Truth\\n| Lots of math | Just high school math is sufficient\\n| Lots of data | We\\'ve seen record-breaking results with <50 items of data\\n| Lots of expensive computers | You can get what you need for state of the art work for free\\n|======\\n```\\n\\nDeep learning is a computer technique to extract and transform data–-with use cases ranging from human speech recognition to animal imagery classification–-by using multiple layers of neural networks. Each of these layers takes its inputs from previous layers and progressively refines them. The layers are trained by algorithms that minimize their errors and improve their accuracy. In this way, the network learns to perform a specified task. We will discuss training algorithms in detail in the next section.\\nDeep learning has power, flexibility, and simplicity. That\\'s why we believe it should be applied across many disciplines. These include the social and physical sciences, the arts, medicine, finance, scientific research, and many more. To give a personal example, despite having no background in medicine, Jeremy started Enlitic, a company that uses deep learning algorithms to diagnose illness and disease.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_text(ctx) in fix_text(passage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3I-U10dB4uL",
        "outputId": "8e55ba86-87e4-4ae6-8386-d3e548eede1c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fix_text(ctx) in fix_text(results[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPWRBaaeCBCB",
        "outputId": "ec4bb1bf-8efa-4534-b798-2d8fc555622d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified MRR@k"
      ],
      "metadata": {
        "id": "LsJtRJvUviFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_mrr(question, results, cutoff=10):\n",
        "    retrieved_passages = results[:cutoff]\n",
        "    highest_rank = 0\n",
        "    for ac in question[\"answer_context\"]:\n",
        "        ctxs = ac.get(\"context\", [])\n",
        "        component_answered = False\n",
        "\n",
        "        for rank, passage in enumerate(retrieved_passages, start=1):\n",
        "            if any(fix_text(ctx) in fix_text(passage) for ctx in ctxs):\n",
        "                highest_rank = max(highest_rank, rank)\n",
        "                component_answered = True\n",
        "                break\n",
        "\n",
        "        if not component_answered: return 0.0\n",
        "\n",
        "    return 1.0/highest_rank if highest_rank > 0 else 0.0"
      ],
      "metadata": {
        "id": "GLExW2wyAAiv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert modified_mrr(question, results[0]) == 0.5"
      ],
      "metadata": {
        "id": "WMtWepncDhJu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert modified_mrr(benchmark['questions'][1], results[0]) == 0"
      ],
      "metadata": {
        "id": "MdDUMKH5DlAt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified Recall@k"
      ],
      "metadata": {
        "id": "2IKzfbHBvkaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modified_recall(question, results, cutoff=10):\n",
        "    retrieved_passages = results[:cutoff]\n",
        "    components_found = []\n",
        "    for ac in question[\"answer_context\"]:\n",
        "        ctxs = ac.get(\"context\", [])\n",
        "        found = False\n",
        "\n",
        "        for rank, passage in enumerate(retrieved_passages, start=1):\n",
        "            if any(fix_text(ctx) in fix_text(passage) for ctx in ctxs):\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        components_found.append(found)\n",
        "\n",
        "\n",
        "    return sum(components_found) / len(components_found)"
      ],
      "metadata": {
        "id": "Dz-YeUfqACjW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert modified_recall(question, results[0]) == 1"
      ],
      "metadata": {
        "id": "0MljOaAmEPh7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert modified_recall(benchmark['questions'][1], results[0]) == 0"
      ],
      "metadata": {
        "id": "mD6gcYk8EVUL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scoring Retrieval Results"
      ],
      "metadata": {
        "id": "iZ2Az1xMAE94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_retrieval(benchmark, results):\n",
        "    mrrs = []\n",
        "    recalls = []\n",
        "\n",
        "    for i,q in enumerate(benchmark['questions']):\n",
        "        mrr = modified_mrr(q, results[i])\n",
        "        recall = modified_recall(q, results[i])\n",
        "        mrrs.append(mrr)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    assert len(mrrs) == len(benchmark['questions'])\n",
        "    assert len(recalls) == len(benchmark['questions'])\n",
        "\n",
        "    mrrs = pd.Series(mrrs)\n",
        "    recalls = pd.Series(recalls)\n",
        "\n",
        "    return mrrs, recalls"
      ],
      "metadata": {
        "id": "ZF98oWArAHWp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrrs, recalls = score_retrieval(benchmark, results)"
      ],
      "metadata": {
        "id": "9Q_pui8yE5FG"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assertion values below come from [these manual validation results](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024-12-13-fastbook-benchmark-results-MANUAL%20VALIDATION.xlsx) obtained by running [this notebook](https://github.com/vishalbakshi/fastbook-benchmark/blob/main/examples/2024_12_13_fastbook_benchmark_results.ipynb)."
      ],
      "metadata": {
        "id": "FykZomkzmAUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert is_close(mrrs.sum(), 96.54365)\n",
        "assert is_close(mrrs.mean(), 0.50546)\n",
        "assert is_close(recalls.sum(), 163.94166)\n",
        "assert is_close(recalls.mean(), 0.858333)"
      ],
      "metadata": {
        "id": "RUmSOPsKAKdQ"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}